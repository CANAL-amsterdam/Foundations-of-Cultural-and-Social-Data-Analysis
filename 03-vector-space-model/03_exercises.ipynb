{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"numpy<2,>=1.13\" \"pandas~=1.1\" \"matplotlib<4,>=2.1\" \"scipy<2,>=0.18\" \"scikit-learn>=0.19\" \"mpl-axes-aligner<2,>=1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31526188",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In this chapter's exercises, we will employ the vector space model to explore a rich and\n",
    "unique collection of '<span class=\"index\">chain letters</span>', which were collected,\n",
    "transcribed, and digitised by {cite:t}`vanarsdale:2019`. Here, we focus on one of the\n",
    "largest chain letter categories: \"luck chain letters\". The recipients of these letters are\n",
    "warned against sin, and the letters often contain prayers and emphasize good behavior according to Christian beliefs. The most characteristic and equally intriguing aspect of these chain letters is their explicit demand to be copied and redistributed to a number of successive recipients. If the recipient does not obey the letter's demands, and thus breaks the chain, he or she will be punished and bad fortune will be inevitable.\n",
    "\n",
    "The following code block loads the corpus into memory. Two lists are created, one for the contents of the letters and one for their dating. The letters are loaded in chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a33a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "letters, years = [], []\n",
    "with open(\"data/chain-letters.csv\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        letters.append(row[\"letter\"])\n",
    "        years.append(int(row[\"year\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e747f",
   "metadata": {},
   "source": [
    "### Easy\n",
    "1. Use the preprocessing functions from section\n",
    "   {ref}`sec-vector-space-model-text-processing` to create (i) a tokenized version of the\n",
    "   corpus, and (ii) a list representing the vocabulary of the corpus. How many unique\n",
    "   words (i.e., word types) are there?\n",
    "2. Transform the tokenized letters into a document-term matrix, and convert the matrix\n",
    "   into a two-dimensional NumPy array. How many word tokens are there in the corpus?\n",
    "3. What is the average number of words per letter? (Hint: use NumPy's `sum()` and `mean()` to\n",
    "   help you with the necessary arithmetic.)\n",
    "\n",
    "### Moderate\n",
    "1. The length of the chain letters has changed considerably over the years. Compute the\n",
    "   average length of letters from before 1950, and compare that to the average length of\n",
    "   letters after 1950. (Hint: convert the list of years into a NumPy array, and use\n",
    "   boolean indexing to slice the document-term matrix.)\n",
    "2. Make a scatter plot to visualize the change in letter length over time. Add a label to\n",
    "   the X and Y axis, and adjust the opacity of the data points for better\n",
    "   visibility. Around what year do the letters suddenly become much longer?\n",
    "3. Not only the length of the letters has changed, but also the contents of the letters.\n",
    "   Early letters in the corpus still have strong religious undertones, while newer\n",
    "   examples put greater emphasis on superstitious beliefs. (The Luck chain letter is\n",
    "   generally believed to stem from the 'Himmelsbrief' (Letter from Heaven), which might\n",
    "   explain these religious undertones.) {cite:t}`vanarsdale:2019` points to an interesting\n",
    "   development of the postscript \"It works!\". The first attestation of this phrase is in\n",
    "   1979, but in a few years time, all succeeding letters end with this statement. Extract\n",
    "   and print the summed frequency of the words *Jesus* and *works* in letters written\n",
    "   before and written after 1950.\n",
    "\n",
    "### Challenging\n",
    "1. Compute the cosine distance between the oldest and the youngest letter in the\n",
    "   corpus. Subsequently, compute the distance between two of the oldest letters (any two\n",
    "   letters from 1906 will do). Finally, compute the distance between the youngest two\n",
    "   letters. Describe your results.\n",
    "2. Use SciPy's `pdist()` function to compute the cosine distances between all letters in the\n",
    "   corpus. Subsequently, transform the resulting condensed distance matrix into a regular\n",
    "   square-form distance matrix. Compute the average distance between letters. Do the same\n",
    "   for letters written before 1950, and compare their mean distance to letters written\n",
    "   after 1950. Describe your results.\n",
    "3. The function `pyplot.matshow()` in Matplotlib takes a matrix or an array as argument and\n",
    "   plots it as an image. Use this function to plot a square-form distance matrix for the entire letter collection. To enhance your visualization, add a color bar using the function\n",
    "   `pyplot.colorbar()`, which provides a mapping between the colors and the cosine\n",
    "   distances. Describe the resulting plot. How many clusters do you observe?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "source_map": [
   16,
   20,
   81,
   100,
   127,
   138,
   142,
   145,
   153,
   162,
   168,
   200,
   206,
   219,
   223,
   250,
   254,
   258,
   262,
   268,
   272,
   274,
   278,
   283,
   287,
   292,
   296,
   327,
   331,
   334,
   338,
   345,
   349,
   379,
   385,
   389,
   400,
   405,
   441,
   467,
   472,
   480,
   493,
   501,
   507,
   513,
   519,
   521,
   532,
   542,
   565,
   569,
   573,
   575,
   579,
   584,
   589,
   601,
   610,
   614,
   619,
   644,
   667,
   690,
   694,
   703,
   710,
   779,
   812,
   816,
   822,
   845,
   849,
   858,
   887,
   907,
   911,
   953,
   963,
   972,
   985,
   998,
   1015,
   1040,
   1042,
   1048,
   1051,
   1055,
   1058,
   1064,
   1068,
   1072,
   1080,
   1084,
   1088,
   1101,
   1104,
   1108,
   1111,
   1138,
   1147,
   1208,
   1210,
   1215,
   1217,
   1221,
   1223,
   1227,
   1230,
   1234,
   1237,
   1241,
   1244,
   1248,
   1251,
   1255,
   1258,
   1262,
   1265,
   1271,
   1273,
   1277,
   1279,
   1283,
   1287,
   1289,
   1297,
   1301,
   1303,
   1307,
   1310,
   1317,
   1320,
   1324,
   1326,
   1336,
   1340,
   1346,
   1348,
   1352,
   1354,
   1358,
   1360,
   1364,
   1366,
   1370,
   1372,
   1381,
   1383,
   1387,
   1391,
   1395,
   1397,
   1401,
   1403,
   1407,
   1410,
   1418,
   1421,
   1425,
   1428,
   1432,
   1435,
   1439,
   1442,
   1446,
   1448,
   1452,
   1454,
   1462,
   1465,
   1469,
   1471,
   1475,
   1478,
   1493,
   1495,
   1499,
   1501,
   1505,
   1507,
   1516,
   1520,
   1524,
   1527
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
